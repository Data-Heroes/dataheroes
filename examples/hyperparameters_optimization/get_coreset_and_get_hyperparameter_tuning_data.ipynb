{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9f7451827f8411",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f7ff736b2e8de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:03.807376Z",
     "start_time": "2024-08-27T15:40:03.801893Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import time\n",
    "\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dataheroes import CoresetTreeServiceDTC, DataTuningParamsClassification\n",
    "\n",
    "encoding = \"ISO-8859-1\"\n",
    "# surpress DeprecationWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "model_class = xgb.XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9cae3ca8a674e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b743efc9a576c60",
   "metadata": {},
   "source": [
    "#### Load Credit Card Fraud Dataset\n",
    "To view more information about the dataset please refer to the next <a href=\"https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\"> link  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "689fc860d82165b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:04.545183Z",
     "start_time": "2024-08-27T15:40:03.818335Z"
    }
   },
   "outputs": [],
   "source": [
    "# public folder on Google drive with data\n",
    "url = \"https://drive.google.com/drive/u/0/folders/1x7wSSs3P195Cu4VtylhqHOypwSKQg1OA\"\n",
    "# create local data folder\n",
    "data_path = pathlib.Path('../data/credit_card_fraud_detection/generated')\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "# download files\n",
    "if not (data_path / 'creditcard.csv').exists():\n",
    "    gdown.download_folder(url, quiet=True, use_cookies=False, output=str(data_path))\n",
    "\n",
    "# load data to the memory\n",
    "df = pd.read_csv(data_path / 'creditcard.csv')\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X = X.values\n",
    "y = y.to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "887929c025c5cbe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:04.593129Z",
     "start_time": "2024-08-27T15:40:04.569341Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fab2b26617193b2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:04.710953Z",
     "start_time": "2024-08-27T15:40:04.634331Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 256326, Test size: 28481\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test 90/10 randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d006d87408973d5c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9651dd4dead2f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:04.738669Z",
     "start_time": "2024-08-27T15:40:04.733299Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(X, y, w, params):\n",
    "    \"\"\"\n",
    "    Train a model using the given parameters\n",
    "    Returns the trained model\n",
    "    \"\"\"\n",
    "    model = model_class(**params, verbose=0)\n",
    "    model.fit(X=X, y=y, sample_weight=w)\n",
    "    return model \n",
    "\n",
    "def run_gridsearch(X, y, w, splitter, params, param_grid, grid_model, refit=True):\n",
    "    \"\"\"\n",
    "    Train a model using a grid search\n",
    "    Returns the best estimator\n",
    "    \"\"\"\n",
    "\n",
    "    model = model_class(**params, verbose=3)\n",
    "    # if grid_model name is bayesian we need to pass n_iter:\n",
    "    if grid_model.__name__ == 'BayesSearchCV':\n",
    "        grid_search = grid_model(model, param_grid, cv=splitter, verbose=3, n_iter=20, scoring='average_precision', refit=refit)\n",
    "    else:\n",
    "        grid_search = grid_model(model, param_grid, cv=splitter, verbose=3, scoring='average_precision', refit=refit)\n",
    "    grid_search.fit(X, y, sample_weight=w)\n",
    "    if refit:\n",
    "        return grid_search.best_estimator_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    Evaluate a model using the test set\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        The model to evaluate\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        The evaluation metrics\n",
    "    \"\"\"\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "    prediction_proba = model.predict_proba(X_test)\n",
    "    # compute scores\n",
    "    balanced_acc = balanced_accuracy_score(y_test, prediction)\n",
    "    f1 = f1_score(y_test, prediction)\n",
    "    precision = precision_score(y_test, prediction)\n",
    "    recall = recall_score(y_test, prediction)\n",
    "    roc_auc = roc_auc_score(y_test, prediction_proba[:,1],average='weighted')\n",
    "    auprc = average_precision_score(y_test, prediction_proba[:,1],average='weighted')\n",
    "    log_loss_score = log_loss(y_test, prediction_proba[:,1])\n",
    "    return balanced_acc, f1, precision, recall, roc_auc, auprc, log_loss_score\n",
    "\n",
    "def run_coreset_gridsearch(grid_model, stats, name='gridsearch'):\n",
    "    \"\"\"\n",
    "    Run grid search on the Coreset data\n",
    "    Parameters\n",
    "    ----------\n",
    "    grid_model : GridSearchCV\n",
    "        The grid search model to use\n",
    "    stats : dict\n",
    "        The dictionary to store the results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The updated stats dictionary and the model parameters\n",
    "    \"\"\"\n",
    "    tuning_data = service_obj.get_hyperparameter_tuning_data(level=2)\n",
    "    refit_data = service_obj.get_coreset(level=2)\n",
    "    # train using the coreset\n",
    "    start_time = time.time()\n",
    "    # When using this method for hyperparameter tuning with cross-validation, such as with Scikit-learn's GridSearchCV,\n",
    "    # we must set `refit=False` because the returned dataset (X, y, and w) includes both training and validation data,\n",
    "    # due to the use of a splitter. The dataset is structured as a concatenation of the training data for the first fold,\n",
    "    # training data for the second fold ... validation data for the first fold, and so on.\n",
    "    # By default, GridSearchCV refits the estimator on the entire dataset, not just the training portion, and this behavior \n",
    "    # cannot be changed. Therefore, refitting in this case would be incorrect.\n",
    "    # Refitting should be handled manually after cross-validation by calling `get_coreset` with the same parameters to \n",
    "    # retrieve the correct training data, and then fitting the model on this data using the best hyperparameters found \n",
    "    # from the cross-validation process.\n",
    "    best_params = run_gridsearch(tuning_data['X'], tuning_data['y'], tuning_data['w'], tuning_data['splitter'], tuning_data['model_params'], param_grid, grid_model, refit=False)\n",
    "    model = model_class(**best_params, verbose=3)\n",
    "    tree_total_time = time.time() - start_time\n",
    "    # refit the model on the refit_data\n",
    "    model.fit(refit_data['X'], refit_data['y'], sample_weight=refit_data['w'])\n",
    "    # evaluate the model\n",
    "    stats[f\"Coreset_{name}\"] = evaluate_model(model)\n",
    "    stats[f\"Coreset_{name}\"]+= (tree_total_time,)\n",
    "    return stats, tuning_data['model_params']\n",
    "\n",
    "def run_random_gridsearch(grid_model, model_params, stats, name='gridsearch'):\n",
    "    \"\"\"\n",
    "    Run grid search on a random sample of the same size as the coreset\n",
    "    Parameters\n",
    "    ----------\n",
    "    grid_model : GridSearchCV\n",
    "        The grid search model to use\n",
    "    model_params : dict\n",
    "        The model parameters\n",
    "    stats : dict\n",
    "        The dictionary to store the results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The updated stats dictionary\n",
    "    \"\"\"\n",
    "    num_samples = service_obj.get_coreset_size(level=2)\n",
    "    # train using a random sample of size num_samples\n",
    "    idx = np.random.choice(X_train.shape[0], num_samples, replace=False)\n",
    "    random_start_time = time.time()\n",
    "    # drop target from df test and select only idx\n",
    "    random_train = X_train[idx]\n",
    "    random_train_target = y_train[idx]\n",
    "    model = run_gridsearch(random_train, random_train_target, None, 4, model_params, param_grid, grid_model)\n",
    "    # evaluate the model\n",
    "    stats[f\"Random_sample_{name}\"] = evaluate_model(model)\n",
    "    random_total_time = time.time() - random_start_time\n",
    "    stats[f\"Random_sample_{name}\"]+= (random_total_time,)\n",
    "    print(f\"Trained {grid_model} and evaluated for level\", 2)\n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96223ff4363d1d4c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdcb29466679b2a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Building the CoresetTreeServiceDTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15ffaf78a58dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:05.636725Z",
     "start_time": "2024-08-27T15:40:04.745136Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-27 18:40:04 Build Started.\n",
      "2024-08-27 18:40:05 Completed chunk #1, \u001b[33m(chunk was built in 0.206 seconds)\u001b[00m\n",
      "2024-08-27 18:40:05 Completed chunk #2, \u001b[33m(chunk was built in 0.014 seconds)\u001b[00m\n",
      "2024-08-27 18:40:05 Completed chunk #3, \u001b[33m(chunk was built in 0.015 seconds)\u001b[00m\n",
      "2024-08-27 18:40:05 Completed chunk #4, \u001b[33m(chunk was built in 0.013 seconds)\u001b[00m\n",
      "2024-08-27 18:40:05 Build Completed in: 0:00:00.835.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dataheroes.services.coreset_tree.dtc.CoresetTreeServiceDTC at 0x345b9d090>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model params for classification\n",
    "clf_params = {\n",
    "    'n_estimators': 500,\n",
    "}\n",
    "\n",
    "service_obj = CoresetTreeServiceDTC(\n",
    "    optimized_for='training',\n",
    "    chunk_size=X_train.shape[0] // 4,\n",
    "    data_tuning_params=DataTuningParamsClassification(coreset_size=[0.05]),\n",
    "    model_cls=model_class,\n",
    ")\n",
    "service_obj.build(X_train, y_train, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "137fc1582c4cf0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:06.250819Z",
     "start_time": "2024-08-27T15:40:05.671210Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': PosixPath('/Users/mike/DataHeroes/dh-library/examples/hyperparameters_optimization/training_tree_20240827_154005.png')}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "service_obj.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59305873218cbdea",
   "metadata": {},
   "source": [
    "##### Training on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65eebc1118aa1c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:08.113956Z",
     "start_time": "2024-08-27T15:40:06.281330Z"
    }
   },
   "outputs": [],
   "source": [
    "stats = dict()\n",
    "# train using the full dataset\n",
    "full_start_time = time.time()\n",
    "model = train_model(X_train, y_train, None, clf_params)\n",
    "full_total_time = time.time() - full_start_time\n",
    "# evaluate the model\n",
    "stats['Full_data'] = evaluate_model(model)\n",
    "stats['Full_data'] += (full_total_time,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a71d0d9c95959",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Training the tree on levels 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7a9d6122932ebde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:09.265998Z",
     "start_time": "2024-08-27T15:40:08.137691Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for level in [0, 1, 2]:\n",
    "    coreset = service_obj.get_coreset(level=level, as_df=True)\n",
    "    # train using the coreset\n",
    "    start_time = time.time()\n",
    "    model = train_model(coreset['X'], coreset['y'], coreset['w'], clf_params)\n",
    "    tree_total_time = time.time() - start_time\n",
    "    # evaluate the model\n",
    "    stats[f\"Coreset_lvl_{level}\"] = evaluate_model(model)\n",
    "    stats[f\"Coreset_lvl_{level}\"] += (tree_total_time,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e77dcd7f416af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Training on random samples of the same size as the Coreset tree levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bacc99cf72b89a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:09.778742Z",
     "start_time": "2024-08-27T15:40:09.289552Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for level in [0, 1, 2]:\n",
    "    coreset_size = service_obj.get_coreset_size(level=level)\n",
    "    # train using a random sample of size num_samples\n",
    "    idx = np.random.choice(X_train.shape[0], coreset_size, replace=False)\n",
    "    # drop target from df test and select only idx\n",
    "    random_train = X_train[idx]\n",
    "    random_train_target = y_train[idx]\n",
    "    random_start_time = time.time()\n",
    "    model = train_model(random_train, random_train_target, None, clf_params)\n",
    "    random_total_time = time.time() - random_start_time\n",
    "    # evaluate the model\n",
    "    stats[f\"Random_sample_{level}\"] = evaluate_model(model)\n",
    "    stats[f\"Random_sample_{level}\"] += (random_total_time,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ed969a4323264",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a25b7ac17962ae0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:09.807180Z",
     "start_time": "2024-08-27T15:40:09.800993Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>Log loss</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full_data</th>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coreset_lvl_0</th>\n",
       "      <td>0.8775</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coreset_lvl_1</th>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coreset_lvl_2</th>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_sample_0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_sample_1</th>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.7708</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_sample_2</th>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Balanced accuracy      F1  Precision  Recall  ROC AUC  \\\n",
       "Full_data                   0.9285  0.9032     0.9545  0.8571   0.9576   \n",
       "Coreset_lvl_0               0.8775  0.8506     0.9737  0.7551   0.9568   \n",
       "Coreset_lvl_1               0.8979  0.8478     0.9070  0.7959   0.9671   \n",
       "Coreset_lvl_2               0.8877  0.8352     0.9048  0.7755   0.9634   \n",
       "Random_sample_0             0.5000  0.0000     0.0000  0.0000   0.9452   \n",
       "Random_sample_1             0.8774  0.7708     0.7872  0.7551   0.9598   \n",
       "Random_sample_2             0.8672  0.7826     0.8372  0.7347   0.9561   \n",
       "\n",
       "                  AUPRC  Log loss  Time  \n",
       "Full_data        0.8844    0.0030  1.78  \n",
       "Coreset_lvl_0    0.8658    0.0034  0.24  \n",
       "Coreset_lvl_1    0.8702    0.0032  0.29  \n",
       "Coreset_lvl_2    0.8692    0.0034  0.34  \n",
       "Random_sample_0  0.5937    0.0095  0.06  \n",
       "Random_sample_1  0.7477    0.0037  0.09  \n",
       "Random_sample_2  0.6548    0.0047  0.12  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataset out of the stats\n",
    "stats_df = pd.DataFrame(stats).T\n",
    "stats_df.columns = ['Balanced accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'AUPRC', 'Log loss', 'Time']\n",
    "stats_df['Time'] = stats_df['Time'].apply(lambda x: round(x, 2))\n",
    "for column in ['Balanced accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'AUPRC', 'Log loss']:\n",
    "    stats_df[column] = stats_df[column].map(lambda x: round(x, 4))\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b7ac4e08a84b10",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d2bda8711147e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:40:09.845384Z",
     "start_time": "2024-08-27T15:40:09.843838Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grid search params\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [500,1000],\n",
    "    'max_depth': [6, 8],\n",
    "}\n",
    "\n",
    "gridsearchCV_stats = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "994a2e3e04c9a005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:43.759513Z",
     "start_time": "2024-08-27T15:40:09.867788Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search on the full dataset\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.840 total time=   1.7s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.854 total time=   1.6s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.851 total time=   1.6s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.872 total time=   1.7s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.840 total time=   2.7s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.855 total time=   2.8s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.852 total time=   2.7s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.871 total time=   2.9s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.839 total time=   1.7s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.855 total time=   1.8s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.854 total time=   2.1s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.872 total time=   1.8s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.838 total time=   2.9s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.856 total time=   2.9s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.855 total time=   3.0s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.871 total time=   3.0s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.840 total time=   1.6s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.852 total time=   1.5s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.849 total time=   1.4s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.871 total time=   1.4s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.840 total time=   2.4s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.852 total time=   2.5s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.849 total time=   2.3s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.871 total time=   2.5s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.835 total time=   1.5s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.848 total time=   1.4s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.852 total time=   1.4s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.859 total time=   1.5s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.837 total time=   2.4s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.849 total time=   2.5s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.853 total time=   2.3s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.858 total time=   2.6s\n",
      "Running grid search on the Coreset data\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.849 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.837 total time=   0.5s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.799 total time=   0.4s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.856 total time=   0.5s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.850 total time=   0.6s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.839 total time=   0.6s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.798 total time=   0.6s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.856 total time=   0.6s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.842 total time=   0.4s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.836 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.795 total time=   0.4s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.851 total time=   0.4s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.845 total time=   0.7s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.837 total time=   0.6s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.795 total time=   0.6s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.853 total time=   0.7s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.851 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.836 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.791 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.853 total time=   0.4s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.851 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.836 total time=   0.5s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.792 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.853 total time=   0.5s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.844 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.835 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.804 total time=   0.4s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.853 total time=   0.3s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.845 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.835 total time=   0.5s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.805 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.853 total time=   0.5s\n",
      "Running grid search on a random sample of the same size as the coreset\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.805 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.801 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.645 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=6, n_estimators=500;, score=0.967 total time=   0.2s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.805 total time=   0.2s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.801 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.645 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=6, n_estimators=1000;, score=0.967 total time=   0.2s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.805 total time=   0.2s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.801 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.645 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=8, n_estimators=500;, score=0.967 total time=   0.2s\n",
      "[CV 1/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.805 total time=   0.2s\n",
      "[CV 2/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.801 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.645 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.1, max_depth=8, n_estimators=1000;, score=0.967 total time=   0.2s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.805 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.801 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.645 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=6, n_estimators=500;, score=0.967 total time=   0.1s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.805 total time=   0.2s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.801 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.645 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=6, n_estimators=1000;, score=0.967 total time=   0.2s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.805 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.801 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.645 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=8, n_estimators=500;, score=0.967 total time=   0.1s\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.805 total time=   0.2s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.801 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.645 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=8, n_estimators=1000;, score=0.967 total time=   0.2s\n",
      "Trained <class 'sklearn.model_selection._search.GridSearchCV'> and evaluated for level 2\n"
     ]
    }
   ],
   "source": [
    "# train using the full dataset\n",
    "full_start_time = time.time()\n",
    "print(\"Running grid search on the full dataset\")\n",
    "model = run_gridsearch(X_train, y_train, None, 4, clf_params, param_grid, GridSearchCV)\n",
    "# evaluate the model\n",
    "gridsearchCV_stats['Full_data_gridsearch'] = evaluate_model(model)\n",
    "full_total_time = time.time() - full_start_time\n",
    "gridsearchCV_stats['Full_data_gridsearch']+= (full_total_time,)\n",
    "# train using the coreset\n",
    "print(\"Running grid search on the Coreset data\")\n",
    "gridsearchCV_stats, model_params = run_coreset_gridsearch(GridSearchCV, gridsearchCV_stats)\n",
    "# train using a random sample of the same size\n",
    "print(\"Running grid search on a random sample of the same size as the coreset\")\n",
    "gridsearchCV_stats = run_random_gridsearch(GridSearchCV, model_params, gridsearchCV_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7621032c256c5e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:43.770315Z",
     "start_time": "2024-08-27T15:41:43.763931Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>Log loss</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full_data_gridsearch</th>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>71.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coreset_gridsearch</th>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>15.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_sample_gridsearch</th>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Balanced accuracy      F1  Precision  Recall  \\\n",
       "Full_data_gridsearch                 0.9183  0.8913     0.9535  0.8367   \n",
       "Coreset_gridsearch                   0.9081  0.8696     0.9302  0.8163   \n",
       "Random_sample_gridsearch             0.8570  0.7778     0.8537  0.7143   \n",
       "\n",
       "                          ROC AUC   AUPRC  Log loss   Time  \n",
       "Full_data_gridsearch       0.9616  0.8814    0.0030  71.89  \n",
       "Coreset_gridsearch         0.9620  0.8692    0.0032  15.54  \n",
       "Random_sample_gridsearch   0.9581  0.7875    0.0036   5.32  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataset out of the stats\n",
    "gridsearch_stats_df = pd.DataFrame(gridsearchCV_stats).T\n",
    "gridsearch_stats_df.columns = ['Balanced accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'AUPRC', 'Log loss', 'Time']\n",
    "gridsearch_stats_df['Time'] = gridsearch_stats_df['Time'].apply(lambda x: round(x, 2))\n",
    "for column in ['Balanced accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'AUPRC', 'Log loss']:\n",
    "    gridsearch_stats_df[column] = gridsearch_stats_df[column].map(lambda x: round(x, 4))\n",
    "gridsearch_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1de1e928e1d75",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bayesian Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2444842b8aa755c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:45:47.526184Z",
     "start_time": "2024-08-27T15:41:43.810933Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bayesian search on the full dataset\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.2293517907592156, max_depth=5, n_estimators=558;, score=0.842 total time=   1.5s\n",
      "[CV 2/4] END learning_rate=0.2293517907592156, max_depth=5, n_estimators=558;, score=0.851 total time=   1.5s\n",
      "[CV 3/4] END learning_rate=0.2293517907592156, max_depth=5, n_estimators=558;, score=0.853 total time=   1.6s\n",
      "[CV 4/4] END learning_rate=0.2293517907592156, max_depth=5, n_estimators=558;, score=0.864 total time=   1.6s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.021805108336808376, max_depth=5, n_estimators=819;, score=0.844 total time=   2.5s\n",
      "[CV 2/4] END learning_rate=0.021805108336808376, max_depth=5, n_estimators=819;, score=0.852 total time=   2.5s\n",
      "[CV 3/4] END learning_rate=0.021805108336808376, max_depth=5, n_estimators=819;, score=0.850 total time=   2.4s\n",
      "[CV 4/4] END learning_rate=0.021805108336808376, max_depth=5, n_estimators=819;, score=0.877 total time=   2.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.06483272136959671, max_depth=6, n_estimators=909;, score=0.843 total time=   2.7s\n",
      "[CV 2/4] END learning_rate=0.06483272136959671, max_depth=6, n_estimators=909;, score=0.858 total time=   2.8s\n",
      "[CV 3/4] END learning_rate=0.06483272136959671, max_depth=6, n_estimators=909;, score=0.850 total time=   2.9s\n",
      "[CV 4/4] END learning_rate=0.06483272136959671, max_depth=6, n_estimators=909;, score=0.872 total time=   2.8s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.1576192690888126, max_depth=5, n_estimators=535;, score=0.841 total time=   1.5s\n",
      "[CV 2/4] END learning_rate=0.1576192690888126, max_depth=5, n_estimators=535;, score=0.852 total time=   1.6s\n",
      "[CV 3/4] END learning_rate=0.1576192690888126, max_depth=5, n_estimators=535;, score=0.853 total time=   1.6s\n",
      "[CV 4/4] END learning_rate=0.1576192690888126, max_depth=5, n_estimators=535;, score=0.864 total time=   1.6s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.2661931344500282, max_depth=6, n_estimators=414;, score=0.840 total time=   1.2s\n",
      "[CV 2/4] END learning_rate=0.2661931344500282, max_depth=6, n_estimators=414;, score=0.849 total time=   1.2s\n",
      "[CV 3/4] END learning_rate=0.2661931344500282, max_depth=6, n_estimators=414;, score=0.847 total time=   1.3s\n",
      "[CV 4/4] END learning_rate=0.2661931344500282, max_depth=6, n_estimators=414;, score=0.874 total time=   1.2s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.11465244443645228, max_depth=5, n_estimators=691;, score=0.843 total time=   2.0s\n",
      "[CV 2/4] END learning_rate=0.11465244443645228, max_depth=5, n_estimators=691;, score=0.851 total time=   2.1s\n",
      "[CV 3/4] END learning_rate=0.11465244443645228, max_depth=5, n_estimators=691;, score=0.851 total time=   2.0s\n",
      "[CV 4/4] END learning_rate=0.11465244443645228, max_depth=5, n_estimators=691;, score=0.873 total time=   2.0s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.06905871747669035, max_depth=5, n_estimators=343;, score=0.844 total time=   1.1s\n",
      "[CV 2/4] END learning_rate=0.06905871747669035, max_depth=5, n_estimators=343;, score=0.850 total time=   1.2s\n",
      "[CV 3/4] END learning_rate=0.06905871747669035, max_depth=5, n_estimators=343;, score=0.848 total time=   1.1s\n",
      "[CV 4/4] END learning_rate=0.06905871747669035, max_depth=5, n_estimators=343;, score=0.876 total time=   1.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.1790320688828388, max_depth=8, n_estimators=628;, score=0.835 total time=   1.8s\n",
      "[CV 2/4] END learning_rate=0.1790320688828388, max_depth=8, n_estimators=628;, score=0.855 total time=   1.8s\n",
      "[CV 3/4] END learning_rate=0.1790320688828388, max_depth=8, n_estimators=628;, score=0.848 total time=   1.8s\n",
      "[CV 4/4] END learning_rate=0.1790320688828388, max_depth=8, n_estimators=628;, score=0.872 total time=   1.8s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.21169622659892506, max_depth=6, n_estimators=953;, score=0.839 total time=   2.4s\n",
      "[CV 2/4] END learning_rate=0.21169622659892506, max_depth=6, n_estimators=953;, score=0.856 total time=   2.3s\n",
      "[CV 3/4] END learning_rate=0.21169622659892506, max_depth=6, n_estimators=953;, score=0.849 total time=   2.5s\n",
      "[CV 4/4] END learning_rate=0.21169622659892506, max_depth=6, n_estimators=953;, score=0.868 total time=   2.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.03615419262847829, max_depth=7, n_estimators=445;, score=0.843 total time=   1.7s\n",
      "[CV 2/4] END learning_rate=0.03615419262847829, max_depth=7, n_estimators=445;, score=0.853 total time=   1.6s\n",
      "[CV 3/4] END learning_rate=0.03615419262847829, max_depth=7, n_estimators=445;, score=0.846 total time=   1.6s\n",
      "[CV 4/4] END learning_rate=0.03615419262847829, max_depth=7, n_estimators=445;, score=0.876 total time=   1.6s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.29857729991222426, max_depth=9, n_estimators=990;, score=0.840 total time=   2.5s\n",
      "[CV 2/4] END learning_rate=0.29857729991222426, max_depth=9, n_estimators=990;, score=0.850 total time=   2.4s\n",
      "[CV 3/4] END learning_rate=0.29857729991222426, max_depth=9, n_estimators=990;, score=0.851 total time=   2.3s\n",
      "[CV 4/4] END learning_rate=0.29857729991222426, max_depth=9, n_estimators=990;, score=0.864 total time=   2.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.13711635877707537, max_depth=6, n_estimators=996;, score=0.840 total time=   2.7s\n",
      "[CV 2/4] END learning_rate=0.13711635877707537, max_depth=6, n_estimators=996;, score=0.858 total time=   2.6s\n",
      "[CV 3/4] END learning_rate=0.13711635877707537, max_depth=6, n_estimators=996;, score=0.849 total time=   2.7s\n",
      "[CV 4/4] END learning_rate=0.13711635877707537, max_depth=6, n_estimators=996;, score=0.869 total time=   2.7s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.01057610976108404, max_depth=10, n_estimators=309;, score=0.829 total time=   1.1s\n",
      "[CV 2/4] END learning_rate=0.01057610976108404, max_depth=10, n_estimators=309;, score=0.856 total time=   1.0s\n",
      "[CV 3/4] END learning_rate=0.01057610976108404, max_depth=10, n_estimators=309;, score=0.831 total time=   1.0s\n",
      "[CV 4/4] END learning_rate=0.01057610976108404, max_depth=10, n_estimators=309;, score=0.865 total time=   0.9s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.2999639991552306, max_depth=10, n_estimators=501;, score=0.840 total time=   1.5s\n",
      "[CV 2/4] END learning_rate=0.2999639991552306, max_depth=10, n_estimators=501;, score=0.854 total time=   1.4s\n",
      "[CV 3/4] END learning_rate=0.2999639991552306, max_depth=10, n_estimators=501;, score=0.848 total time=   1.4s\n",
      "[CV 4/4] END learning_rate=0.2999639991552306, max_depth=10, n_estimators=501;, score=0.866 total time=   1.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.2998616328853931, max_depth=7, n_estimators=342;, score=0.835 total time=   1.1s\n",
      "[CV 2/4] END learning_rate=0.2998616328853931, max_depth=7, n_estimators=342;, score=0.848 total time=   1.1s\n",
      "[CV 3/4] END learning_rate=0.2998616328853931, max_depth=7, n_estimators=342;, score=0.850 total time=   1.1s\n",
      "[CV 4/4] END learning_rate=0.2998616328853931, max_depth=7, n_estimators=342;, score=0.869 total time=   1.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.17242552164249522, max_depth=10, n_estimators=891;, score=0.840 total time=   2.7s\n",
      "[CV 2/4] END learning_rate=0.17242552164249522, max_depth=10, n_estimators=891;, score=0.855 total time=   2.3s\n",
      "[CV 3/4] END learning_rate=0.17242552164249522, max_depth=10, n_estimators=891;, score=0.850 total time=   2.5s\n",
      "[CV 4/4] END learning_rate=0.17242552164249522, max_depth=10, n_estimators=891;, score=0.865 total time=   2.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.298641546310084, max_depth=5, n_estimators=964;, score=0.837 total time=   2.4s\n",
      "[CV 2/4] END learning_rate=0.298641546310084, max_depth=5, n_estimators=964;, score=0.857 total time=   2.4s\n",
      "[CV 3/4] END learning_rate=0.298641546310084, max_depth=5, n_estimators=964;, score=0.853 total time=   2.5s\n",
      "[CV 4/4] END learning_rate=0.298641546310084, max_depth=5, n_estimators=964;, score=0.872 total time=   2.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.01, max_depth=6, n_estimators=1000;, score=0.845 total time=   3.2s\n",
      "[CV 2/4] END learning_rate=0.01, max_depth=6, n_estimators=1000;, score=0.855 total time=   3.1s\n",
      "[CV 3/4] END learning_rate=0.01, max_depth=6, n_estimators=1000;, score=0.837 total time=   3.2s\n",
      "[CV 4/4] END learning_rate=0.01, max_depth=6, n_estimators=1000;, score=0.875 total time=   3.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.08770584782587752, max_depth=7, n_estimators=324;, score=0.844 total time=   1.3s\n",
      "[CV 2/4] END learning_rate=0.08770584782587752, max_depth=7, n_estimators=324;, score=0.852 total time=   1.2s\n",
      "[CV 3/4] END learning_rate=0.08770584782587752, max_depth=7, n_estimators=324;, score=0.847 total time=   1.2s\n",
      "[CV 4/4] END learning_rate=0.08770584782587752, max_depth=7, n_estimators=324;, score=0.874 total time=   1.2s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.09906368927673127, max_depth=9, n_estimators=950;, score=0.839 total time=   2.8s\n",
      "[CV 2/4] END learning_rate=0.09906368927673127, max_depth=9, n_estimators=950;, score=0.855 total time=   2.8s\n",
      "[CV 3/4] END learning_rate=0.09906368927673127, max_depth=9, n_estimators=950;, score=0.847 total time=   2.8s\n",
      "[CV 4/4] END learning_rate=0.09906368927673127, max_depth=9, n_estimators=950;, score=0.870 total time=   2.9s\n",
      "Running bayesian search on the Coreset data\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.19096176429805087, max_depth=9, n_estimators=461;, score=0.848 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.19096176429805087, max_depth=9, n_estimators=461;, score=0.836 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.19096176429805087, max_depth=9, n_estimators=461;, score=0.787 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.19096176429805087, max_depth=9, n_estimators=461;, score=0.855 total time=   0.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.14272044032075917, max_depth=6, n_estimators=931;, score=0.846 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.14272044032075917, max_depth=6, n_estimators=931;, score=0.840 total time=   0.5s\n",
      "[CV 3/4] END learning_rate=0.14272044032075917, max_depth=6, n_estimators=931;, score=0.798 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.14272044032075917, max_depth=6, n_estimators=931;, score=0.857 total time=   0.5s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.0989680599830173, max_depth=10, n_estimators=946;, score=0.847 total time=   0.6s\n",
      "[CV 2/4] END learning_rate=0.0989680599830173, max_depth=10, n_estimators=946;, score=0.832 total time=   0.6s\n",
      "[CV 3/4] END learning_rate=0.0989680599830173, max_depth=10, n_estimators=946;, score=0.793 total time=   0.6s\n",
      "[CV 4/4] END learning_rate=0.0989680599830173, max_depth=10, n_estimators=946;, score=0.857 total time=   0.6s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.1813119041642944, max_depth=8, n_estimators=646;, score=0.847 total time=   0.4s\n",
      "[CV 2/4] END learning_rate=0.1813119041642944, max_depth=8, n_estimators=646;, score=0.839 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.1813119041642944, max_depth=8, n_estimators=646;, score=0.795 total time=   0.4s\n",
      "[CV 4/4] END learning_rate=0.1813119041642944, max_depth=8, n_estimators=646;, score=0.859 total time=   0.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.17964213267783874, max_depth=7, n_estimators=789;, score=0.847 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.17964213267783874, max_depth=7, n_estimators=789;, score=0.838 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.17964213267783874, max_depth=7, n_estimators=789;, score=0.798 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.17964213267783874, max_depth=7, n_estimators=789;, score=0.856 total time=   0.5s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.16134283028361088, max_depth=6, n_estimators=342;, score=0.851 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.16134283028361088, max_depth=6, n_estimators=342;, score=0.844 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.16134283028361088, max_depth=6, n_estimators=342;, score=0.795 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.16134283028361088, max_depth=6, n_estimators=342;, score=0.857 total time=   0.3s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.05284085428330841, max_depth=6, n_estimators=776;, score=0.844 total time=   0.7s\n",
      "[CV 2/4] END learning_rate=0.05284085428330841, max_depth=6, n_estimators=776;, score=0.835 total time=   0.6s\n",
      "[CV 3/4] END learning_rate=0.05284085428330841, max_depth=6, n_estimators=776;, score=0.799 total time=   0.6s\n",
      "[CV 4/4] END learning_rate=0.05284085428330841, max_depth=6, n_estimators=776;, score=0.860 total time=   0.6s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.07506554957332162, max_depth=9, n_estimators=565;, score=0.844 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.07506554957332162, max_depth=9, n_estimators=565;, score=0.831 total time=   0.5s\n",
      "[CV 3/4] END learning_rate=0.07506554957332162, max_depth=9, n_estimators=565;, score=0.796 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.07506554957332162, max_depth=9, n_estimators=565;, score=0.854 total time=   0.5s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.2020409342446156, max_depth=6, n_estimators=404;, score=0.853 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.2020409342446156, max_depth=6, n_estimators=404;, score=0.836 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.2020409342446156, max_depth=6, n_estimators=404;, score=0.804 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.2020409342446156, max_depth=6, n_estimators=404;, score=0.860 total time=   0.3s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.07425141070051668, max_depth=9, n_estimators=822;, score=0.843 total time=   0.8s\n",
      "[CV 2/4] END learning_rate=0.07425141070051668, max_depth=9, n_estimators=822;, score=0.834 total time=   0.6s\n",
      "[CV 3/4] END learning_rate=0.07425141070051668, max_depth=9, n_estimators=822;, score=0.796 total time=   0.6s\n",
      "[CV 4/4] END learning_rate=0.07425141070051668, max_depth=9, n_estimators=822;, score=0.856 total time=   0.7s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.2935511908421786, max_depth=5, n_estimators=311;, score=0.849 total time=   0.4s\n",
      "[CV 2/4] END learning_rate=0.2935511908421786, max_depth=5, n_estimators=311;, score=0.841 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.2935511908421786, max_depth=5, n_estimators=311;, score=0.781 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.2935511908421786, max_depth=5, n_estimators=311;, score=0.851 total time=   0.3s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.01083154287234355, max_depth=5, n_estimators=917;, score=0.842 total time=   0.9s\n",
      "[CV 2/4] END learning_rate=0.01083154287234355, max_depth=5, n_estimators=917;, score=0.822 total time=   0.8s\n",
      "[CV 3/4] END learning_rate=0.01083154287234355, max_depth=5, n_estimators=917;, score=0.785 total time=   0.9s\n",
      "[CV 4/4] END learning_rate=0.01083154287234355, max_depth=5, n_estimators=917;, score=0.866 total time=   0.9s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=6, n_estimators=300;, score=0.851 total time=   0.4s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=6, n_estimators=300;, score=0.834 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=6, n_estimators=300;, score=0.789 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=6, n_estimators=300;, score=0.853 total time=   0.2s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.061125729562986286, max_depth=8, n_estimators=302;, score=0.836 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.061125729562986286, max_depth=8, n_estimators=302;, score=0.829 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.061125729562986286, max_depth=8, n_estimators=302;, score=0.793 total time=   0.4s\n",
      "[CV 4/4] END learning_rate=0.061125729562986286, max_depth=8, n_estimators=302;, score=0.860 total time=   0.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.184077260061166, max_depth=5, n_estimators=665;, score=0.851 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.184077260061166, max_depth=5, n_estimators=665;, score=0.837 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.184077260061166, max_depth=5, n_estimators=665;, score=0.788 total time=   0.4s\n",
      "[CV 4/4] END learning_rate=0.184077260061166, max_depth=5, n_estimators=665;, score=0.857 total time=   0.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.29137632378216344, max_depth=8, n_estimators=454;, score=0.845 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.29137632378216344, max_depth=8, n_estimators=454;, score=0.840 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.29137632378216344, max_depth=8, n_estimators=454;, score=0.800 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.29137632378216344, max_depth=8, n_estimators=454;, score=0.854 total time=   0.3s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.299474388305754, max_depth=10, n_estimators=886;, score=0.843 total time=   0.6s\n",
      "[CV 2/4] END learning_rate=0.299474388305754, max_depth=10, n_estimators=886;, score=0.837 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.299474388305754, max_depth=10, n_estimators=886;, score=0.800 total time=   0.4s\n",
      "[CV 4/4] END learning_rate=0.299474388305754, max_depth=10, n_estimators=886;, score=0.854 total time=   0.5s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.1968818663346093, max_depth=6, n_estimators=387;, score=0.846 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.1968818663346093, max_depth=6, n_estimators=387;, score=0.839 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.1968818663346093, max_depth=6, n_estimators=387;, score=0.794 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.1968818663346093, max_depth=6, n_estimators=387;, score=0.855 total time=   0.3s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.010109796898065493, max_depth=10, n_estimators=686;, score=0.826 total time=   1.1s\n",
      "[CV 2/4] END learning_rate=0.010109796898065493, max_depth=10, n_estimators=686;, score=0.816 total time=   0.9s\n",
      "[CV 3/4] END learning_rate=0.010109796898065493, max_depth=10, n_estimators=686;, score=0.780 total time=   0.9s\n",
      "[CV 4/4] END learning_rate=0.010109796898065493, max_depth=10, n_estimators=686;, score=0.856 total time=   1.0s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.1026470265593144, max_depth=5, n_estimators=930;, score=0.854 total time=   0.7s\n",
      "[CV 2/4] END learning_rate=0.1026470265593144, max_depth=5, n_estimators=930;, score=0.833 total time=   0.5s\n",
      "[CV 3/4] END learning_rate=0.1026470265593144, max_depth=5, n_estimators=930;, score=0.795 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.1026470265593144, max_depth=5, n_estimators=930;, score=0.856 total time=   0.6s\n",
      "Running bayesian search on a random sample of the same size as the coreset\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.13548925780571835, max_depth=6, n_estimators=528;, score=0.800 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.13548925780571835, max_depth=6, n_estimators=528;, score=0.816 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.13548925780571835, max_depth=6, n_estimators=528;, score=0.877 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.13548925780571835, max_depth=6, n_estimators=528;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.07746720121618186, max_depth=8, n_estimators=332;, score=0.801 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.07746720121618186, max_depth=8, n_estimators=332;, score=0.831 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.07746720121618186, max_depth=8, n_estimators=332;, score=0.877 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.07746720121618186, max_depth=8, n_estimators=332;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.12072671692841204, max_depth=5, n_estimators=710;, score=0.800 total time=   0.2s\n",
      "[CV 2/4] END learning_rate=0.12072671692841204, max_depth=5, n_estimators=710;, score=0.823 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.12072671692841204, max_depth=5, n_estimators=710;, score=0.877 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.12072671692841204, max_depth=5, n_estimators=710;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.09446357107183177, max_depth=8, n_estimators=429;, score=0.800 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.09446357107183177, max_depth=8, n_estimators=429;, score=0.824 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.09446357107183177, max_depth=8, n_estimators=429;, score=0.877 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.09446357107183177, max_depth=8, n_estimators=429;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.18485865840132798, max_depth=6, n_estimators=538;, score=0.800 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.18485865840132798, max_depth=6, n_estimators=538;, score=0.821 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.18485865840132798, max_depth=6, n_estimators=538;, score=0.877 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.18485865840132798, max_depth=6, n_estimators=538;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.10923755636847868, max_depth=8, n_estimators=406;, score=0.800 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.10923755636847868, max_depth=8, n_estimators=406;, score=0.822 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.10923755636847868, max_depth=8, n_estimators=406;, score=0.877 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.10923755636847868, max_depth=8, n_estimators=406;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.021695019269520645, max_depth=8, n_estimators=762;, score=0.801 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.021695019269520645, max_depth=8, n_estimators=762;, score=0.827 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.021695019269520645, max_depth=8, n_estimators=762;, score=0.927 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.021695019269520645, max_depth=8, n_estimators=762;, score=0.502 total time=   0.3s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.053592187827163164, max_depth=6, n_estimators=415;, score=0.800 total time=   0.1s\n",
      "[CV 2/4] END learning_rate=0.053592187827163164, max_depth=6, n_estimators=415;, score=0.829 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.053592187827163164, max_depth=6, n_estimators=415;, score=0.877 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.053592187827163164, max_depth=6, n_estimators=415;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.1998861482472926, max_depth=9, n_estimators=729;, score=0.800 total time=   0.2s\n",
      "[CV 2/4] END learning_rate=0.1998861482472926, max_depth=9, n_estimators=729;, score=0.819 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.1998861482472926, max_depth=9, n_estimators=729;, score=0.877 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.1998861482472926, max_depth=9, n_estimators=729;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.14812652791545533, max_depth=5, n_estimators=423;, score=0.800 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.14812652791545533, max_depth=5, n_estimators=423;, score=0.823 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.14812652791545533, max_depth=5, n_estimators=423;, score=0.877 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.14812652791545533, max_depth=5, n_estimators=423;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.01, max_depth=8, n_estimators=1000;, score=0.801 total time=   0.6s\n",
      "[CV 2/4] END learning_rate=0.01, max_depth=8, n_estimators=1000;, score=0.831 total time=   0.4s\n",
      "[CV 3/4] END learning_rate=0.01, max_depth=8, n_estimators=1000;, score=0.927 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.01, max_depth=8, n_estimators=1000;, score=0.502 total time=   0.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.2980406831464518, max_depth=9, n_estimators=305;, score=0.800 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.2980406831464518, max_depth=9, n_estimators=305;, score=0.827 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.2980406831464518, max_depth=9, n_estimators=305;, score=0.810 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.2980406831464518, max_depth=9, n_estimators=305;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.01, max_depth=10, n_estimators=300;, score=0.800 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.01, max_depth=10, n_estimators=300;, score=0.800 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.01, max_depth=10, n_estimators=300;, score=0.710 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.01, max_depth=10, n_estimators=300;, score=0.501 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.26310773881206134, max_depth=7, n_estimators=461;, score=0.800 total time=   0.3s\n",
      "[CV 2/4] END learning_rate=0.26310773881206134, max_depth=7, n_estimators=461;, score=0.821 total time=   0.1s\n",
      "[CV 3/4] END learning_rate=0.26310773881206134, max_depth=7, n_estimators=461;, score=0.877 total time=   0.1s\n",
      "[CV 4/4] END learning_rate=0.26310773881206134, max_depth=7, n_estimators=461;, score=0.502 total time=   0.1s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.01, max_depth=7, n_estimators=1000;, score=0.801 total time=   0.6s\n",
      "[CV 2/4] END learning_rate=0.01, max_depth=7, n_estimators=1000;, score=0.831 total time=   0.5s\n",
      "[CV 3/4] END learning_rate=0.01, max_depth=7, n_estimators=1000;, score=0.927 total time=   0.5s\n",
      "[CV 4/4] END learning_rate=0.01, max_depth=7, n_estimators=1000;, score=0.502 total time=   0.4s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=5, n_estimators=1000;, score=0.800 total time=   0.4s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=5, n_estimators=1000;, score=0.822 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=5, n_estimators=1000;, score=0.877 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=5, n_estimators=1000;, score=0.502 total time=   0.2s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.07644499068161449, max_depth=10, n_estimators=1000;, score=0.800 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.07644499068161449, max_depth=10, n_estimators=1000;, score=0.824 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.07644499068161449, max_depth=10, n_estimators=1000;, score=0.877 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.07644499068161449, max_depth=10, n_estimators=1000;, score=0.502 total time=   0.2s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=7, n_estimators=874;, score=0.800 total time=   0.4s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=7, n_estimators=874;, score=0.822 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=7, n_estimators=874;, score=0.877 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=7, n_estimators=874;, score=0.502 total time=   0.2s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.3, max_depth=9, n_estimators=1000;, score=0.800 total time=   0.4s\n",
      "[CV 2/4] END learning_rate=0.3, max_depth=9, n_estimators=1000;, score=0.822 total time=   0.2s\n",
      "[CV 3/4] END learning_rate=0.3, max_depth=9, n_estimators=1000;, score=0.877 total time=   0.2s\n",
      "[CV 4/4] END learning_rate=0.3, max_depth=9, n_estimators=1000;, score=0.502 total time=   0.2s\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV 1/4] END learning_rate=0.036691433904304044, max_depth=6, n_estimators=919;, score=0.800 total time=   0.5s\n",
      "[CV 2/4] END learning_rate=0.036691433904304044, max_depth=6, n_estimators=919;, score=0.829 total time=   0.3s\n",
      "[CV 3/4] END learning_rate=0.036691433904304044, max_depth=6, n_estimators=919;, score=0.877 total time=   0.3s\n",
      "[CV 4/4] END learning_rate=0.036691433904304044, max_depth=6, n_estimators=919;, score=0.502 total time=   0.3s\n",
      "Trained <class 'skopt.searchcv.BayesSearchCV'> and evaluated for level 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>Log loss</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full_data_bayesian</th>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>168.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coreset_bayesian</th>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>47.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_sample_bayesian</th>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.7827</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>26.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Balanced accuracy      F1  Precision  Recall  ROC AUC  \\\n",
       "Full_data_bayesian                 0.9286  0.9130     0.9767  0.8571   0.9723   \n",
       "Coreset_bayesian                   0.9081  0.8602     0.9091  0.8163   0.9655   \n",
       "Random_sample_bayesian             0.8774  0.7872     0.8222  0.7551   0.9673   \n",
       "\n",
       "                         AUPRC  Log loss    Time  \n",
       "Full_data_bayesian      0.8831    0.0023  168.99  \n",
       "Coreset_bayesian        0.8739    0.0031   47.02  \n",
       "Random_sample_bayesian  0.7827    0.0036   26.75  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "param_grid = {\n",
    "    'learning_rate': Real(0.01, 0.3),\n",
    "    'n_estimators': Integer(300, 1000),\n",
    "    'max_depth': Integer(5, 10),\n",
    "}\n",
    "bayesianCV_stats = dict()\n",
    "# train using the full dataset\n",
    "print(\"Running bayesian search on the full dataset\")\n",
    "full_start_time = time.time()\n",
    "model = run_gridsearch(X_train, y_train, None, 4, clf_params, param_grid, BayesSearchCV)\n",
    "# evaluate the model\n",
    "bayesianCV_stats['Full_data_bayesian'] = evaluate_model(model)\n",
    "full_total_time = time.time() - full_start_time\n",
    "bayesianCV_stats['Full_data_bayesian']+= (full_total_time,)\n",
    "# train using the coreset\n",
    "print(\"Running bayesian search on the Coreset data\")\n",
    "bayesianCV_stats, model_params = run_coreset_gridsearch(BayesSearchCV, bayesianCV_stats, name='bayesian')\n",
    "# train using a random sample of the same size\n",
    "print(\"Running bayesian search on a random sample of the same size as the coreset\")\n",
    "bayesianCV_stats = run_random_gridsearch(BayesSearchCV, model_params, bayesianCV_stats, name='bayesian')\n",
    "# make a dataset out of the stats\n",
    "bayesianCV_stats_df = pd.DataFrame(bayesianCV_stats).T\n",
    "bayesianCV_stats_df.columns = ['Balanced accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'AUPRC', 'Log loss', 'Time']\n",
    "bayesianCV_stats_df['Time'] = bayesianCV_stats_df['Time'].apply(lambda x: round(x, 2))\n",
    "for column in ['Balanced accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'AUPRC', 'Log loss']:\n",
    "    bayesianCV_stats_df[column] = bayesianCV_stats_df[column].map(lambda x: round(x, 4))\n",
    "bayesianCV_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f851b469e2cc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Optuna Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59cee0b375890551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:48:09.563140Z",
     "start_time": "2024-08-27T15:45:47.583708Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 18:45:47,787] A new study created in memory with name: no-name-7e254c30-8c43-4f15-ae95-15155e0254ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optuna search on the full data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 18:45:49,077] Trial 0 finished with value: 0.881085516439169 and parameters: {'learning_rate': 0.08736236644909298, 'n_estimators': 802, 'depth': 10}. Best is trial 0 with value: 0.881085516439169.\n",
      "[I 2024-08-27 18:45:50,300] Trial 1 finished with value: 0.8818070122691462 and parameters: {'learning_rate': 0.07068593164344639, 'n_estimators': 895, 'depth': 7}. Best is trial 1 with value: 0.8818070122691462.\n",
      "[I 2024-08-27 18:45:51,173] Trial 2 finished with value: 0.8824396595831738 and parameters: {'learning_rate': 0.27301755672906036, 'n_estimators': 938, 'depth': 10}. Best is trial 2 with value: 0.8824396595831738.\n",
      "[I 2024-08-27 18:45:52,029] Trial 3 finished with value: 0.8800830529345728 and parameters: {'learning_rate': 0.23363686288084906, 'n_estimators': 935, 'depth': 12}. Best is trial 2 with value: 0.8824396595831738.\n",
      "[I 2024-08-27 18:45:52,915] Trial 4 finished with value: 0.8769196371100807 and parameters: {'learning_rate': 0.27436990939321354, 'n_estimators': 963, 'depth': 9}. Best is trial 2 with value: 0.8824396595831738.\n",
      "[I 2024-08-27 18:45:53,744] Trial 5 finished with value: 0.8787043390737478 and parameters: {'learning_rate': 0.2823929913125881, 'n_estimators': 367, 'depth': 9}. Best is trial 2 with value: 0.8824396595831738.\n",
      "[I 2024-08-27 18:45:54,821] Trial 6 finished with value: 0.8785617389753306 and parameters: {'learning_rate': 0.1357900320936332, 'n_estimators': 639, 'depth': 8}. Best is trial 2 with value: 0.8824396595831738.\n",
      "[I 2024-08-27 18:45:56,313] Trial 7 finished with value: 0.8839312643601814 and parameters: {'learning_rate': 0.08395259124694443, 'n_estimators': 480, 'depth': 10}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:45:57,163] Trial 8 finished with value: 0.8785011899644721 and parameters: {'learning_rate': 0.29443200685176324, 'n_estimators': 514, 'depth': 10}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:45:58,065] Trial 9 finished with value: 0.8747061649972491 and parameters: {'learning_rate': 0.2948635498495842, 'n_estimators': 728, 'depth': 5}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:45:59,765] Trial 10 finished with value: 0.8774192874843301 and parameters: {'learning_rate': 0.011782470595567668, 'n_estimators': 342, 'depth': 12}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:00,803] Trial 11 finished with value: 0.8837008172865035 and parameters: {'learning_rate': 0.20385238443778345, 'n_estimators': 528, 'depth': 11}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:01,730] Trial 12 finished with value: 0.8815121102755215 and parameters: {'learning_rate': 0.19025384763776873, 'n_estimators': 521, 'depth': 11}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:02,672] Trial 13 finished with value: 0.8805037730661995 and parameters: {'learning_rate': 0.14966899744734563, 'n_estimators': 514, 'depth': 11}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:03,570] Trial 14 finished with value: 0.8819067201481096 and parameters: {'learning_rate': 0.1968388972953399, 'n_estimators': 438, 'depth': 7}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:04,840] Trial 15 finished with value: 0.8829143221999314 and parameters: {'learning_rate': 0.10249609512901266, 'n_estimators': 643, 'depth': 11}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:06,542] Trial 16 finished with value: 0.8831379012528844 and parameters: {'learning_rate': 0.03697481474494816, 'n_estimators': 579, 'depth': 8}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:07,455] Trial 17 finished with value: 0.8817631543934 and parameters: {'learning_rate': 0.19787048209618058, 'n_estimators': 438, 'depth': 12}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:08,687] Trial 18 finished with value: 0.8831188397873652 and parameters: {'learning_rate': 0.11936307763121143, 'n_estimators': 742, 'depth': 10}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:10,081] Trial 19 finished with value: 0.8824118467598068 and parameters: {'learning_rate': 0.05368171842041025, 'n_estimators': 401, 'depth': 5}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:10,955] Trial 20 finished with value: 0.8805071391342815 and parameters: {'learning_rate': 0.17751974526961156, 'n_estimators': 312, 'depth': 11}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:13,567] Trial 21 finished with value: 0.882676008866675 and parameters: {'learning_rate': 0.023387788234908384, 'n_estimators': 576, 'depth': 8}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:15,469] Trial 22 finished with value: 0.8833132189542837 and parameters: {'learning_rate': 0.043849619014256505, 'n_estimators': 582, 'depth': 7}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:16,394] Trial 23 finished with value: 0.878906653642746 and parameters: {'learning_rate': 0.23097386404399908, 'n_estimators': 563, 'depth': 6}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:17,684] Trial 24 finished with value: 0.8833982796957507 and parameters: {'learning_rate': 0.06289668003305625, 'n_estimators': 481, 'depth': 7}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:18,918] Trial 25 finished with value: 0.8825302643115682 and parameters: {'learning_rate': 0.08058025598741417, 'n_estimators': 455, 'depth': 9}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:20,060] Trial 26 finished with value: 0.8826817747725182 and parameters: {'learning_rate': 0.11209203168966919, 'n_estimators': 478, 'depth': 9}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:21,008] Trial 27 finished with value: 0.882490158633054 and parameters: {'learning_rate': 0.15919098057111053, 'n_estimators': 392, 'depth': 6}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:22,475] Trial 28 finished with value: 0.8820300327728392 and parameters: {'learning_rate': 0.05904049313019934, 'n_estimators': 698, 'depth': 6}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:23,716] Trial 29 finished with value: 0.8812715707925978 and parameters: {'learning_rate': 0.09150856205060301, 'n_estimators': 627, 'depth': 10}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:24,676] Trial 30 finished with value: 0.8820281659519815 and parameters: {'learning_rate': 0.2262640989523301, 'n_estimators': 836, 'depth': 11}. Best is trial 7 with value: 0.8839312643601814.\n",
      "[I 2024-08-27 18:46:26,176] Trial 31 finished with value: 0.884099500974368 and parameters: {'learning_rate': 0.04594992330528035, 'n_estimators': 548, 'depth': 7}. Best is trial 31 with value: 0.884099500974368.\n",
      "[I 2024-08-27 18:46:27,722] Trial 32 finished with value: 0.8828016691195947 and parameters: {'learning_rate': 0.0732030930240288, 'n_estimators': 488, 'depth': 7}. Best is trial 31 with value: 0.884099500974368.\n",
      "[I 2024-08-27 18:46:29,813] Trial 33 finished with value: 0.8848418419336338 and parameters: {'learning_rate': 0.03533133817641757, 'n_estimators': 541, 'depth': 8}. Best is trial 33 with value: 0.8848418419336338.\n",
      "[I 2024-08-27 18:46:31,895] Trial 34 finished with value: 0.884436109562329 and parameters: {'learning_rate': 0.027045221321433853, 'n_estimators': 555, 'depth': 8}. Best is trial 33 with value: 0.8848418419336338.\n",
      "[I 2024-08-27 18:46:33,952] Trial 35 finished with value: 0.8836925155571952 and parameters: {'learning_rate': 0.031522644404629444, 'n_estimators': 671, 'depth': 8}. Best is trial 33 with value: 0.8848418419336338.\n",
      "[I 2024-08-27 18:46:36,571] Trial 36 finished with value: 0.884172171061319 and parameters: {'learning_rate': 0.025859504549174732, 'n_estimators': 546, 'depth': 8}. Best is trial 33 with value: 0.8848418419336338.\n",
      "[I 2024-08-27 18:46:39,821] Trial 37 finished with value: 0.8852922561691332 and parameters: {'learning_rate': 0.011126943902020002, 'n_estimators': 594, 'depth': 8}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:46:42,999] Trial 38 finished with value: 0.8852461266611016 and parameters: {'learning_rate': 0.010785205332854006, 'n_estimators': 612, 'depth': 8}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:46:46,492] Trial 39 finished with value: 0.8846330252124476 and parameters: {'learning_rate': 0.015922429200469542, 'n_estimators': 786, 'depth': 9}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:46:50,437] Trial 40 finished with value: 0.883915182386986 and parameters: {'learning_rate': 0.013843015455143704, 'n_estimators': 794, 'depth': 9}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:46:53,683] Trial 41 finished with value: 0.8841445538369466 and parameters: {'learning_rate': 0.015321458786404592, 'n_estimators': 605, 'depth': 8}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:46:55,573] Trial 42 finished with value: 0.8832813655699518 and parameters: {'learning_rate': 0.03724984865157199, 'n_estimators': 676, 'depth': 9}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:46:57,706] Trial 43 finished with value: 0.8851598677024249 and parameters: {'learning_rate': 0.02465663121216588, 'n_estimators': 998, 'depth': 9}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:01,723] Trial 44 finished with value: 0.8832139587717265 and parameters: {'learning_rate': 0.012891639262675758, 'n_estimators': 924, 'depth': 9}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:03,321] Trial 45 finished with value: 0.8814733593515013 and parameters: {'learning_rate': 0.05374592861998877, 'n_estimators': 983, 'depth': 10}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:07,769] Trial 46 finished with value: 0.883964166164171 and parameters: {'learning_rate': 0.01053469523533697, 'n_estimators': 876, 'depth': 9}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:09,337] Trial 47 finished with value: 0.8833686716314726 and parameters: {'learning_rate': 0.044613769927373474, 'n_estimators': 751, 'depth': 8}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:10,823] Trial 48 finished with value: 0.8851999465339414 and parameters: {'learning_rate': 0.07283007360447692, 'n_estimators': 786, 'depth': 8}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:12,000] Trial 49 finished with value: 0.882356492216023 and parameters: {'learning_rate': 0.07347890475617742, 'n_estimators': 884, 'depth': 8}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:13,422] Trial 50 finished with value: 0.8847435818726738 and parameters: {'learning_rate': 0.0597301197130242, 'n_estimators': 847, 'depth': 7}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:14,480] Trial 51 finished with value: 0.8808592027105114 and parameters: {'learning_rate': 0.09547132154602722, 'n_estimators': 832, 'depth': 7}. Best is trial 37 with value: 0.8852922561691332.\n",
      "[I 2024-08-27 18:47:15,965] Trial 52 finished with value: 0.8856957539501197 and parameters: {'learning_rate': 0.06457111979638665, 'n_estimators': 947, 'depth': 8}. Best is trial 52 with value: 0.8856957539501197.\n",
      "[I 2024-08-27 18:47:18,161] Trial 53 finished with value: 0.8853758972903614 and parameters: {'learning_rate': 0.03549826510188932, 'n_estimators': 924, 'depth': 8}. Best is trial 52 with value: 0.8856957539501197.\n",
      "[I 2024-08-27 18:47:19,631] Trial 54 finished with value: 0.8858787135523333 and parameters: {'learning_rate': 0.06825023203675772, 'n_estimators': 996, 'depth': 8}. Best is trial 54 with value: 0.8858787135523333.\n",
      "[I 2024-08-27 18:47:20,718] Trial 55 finished with value: 0.8836664537261439 and parameters: {'learning_rate': 0.12674122958895426, 'n_estimators': 956, 'depth': 8}. Best is trial 54 with value: 0.8858787135523333.\n",
      "[I 2024-08-27 18:47:22,147] Trial 56 finished with value: 0.8831693947291354 and parameters: {'learning_rate': 0.06819623806459855, 'n_estimators': 919, 'depth': 8}. Best is trial 54 with value: 0.8858787135523333.\n",
      "[I 2024-08-27 18:47:23,145] Trial 57 finished with value: 0.8840542714234161 and parameters: {'learning_rate': 0.10515961747009911, 'n_estimators': 960, 'depth': 7}. Best is trial 54 with value: 0.8858787135523333.\n",
      "[I 2024-08-27 18:47:23,979] Trial 58 finished with value: 0.8842027239745585 and parameters: {'learning_rate': 0.25614084680330396, 'n_estimators': 911, 'depth': 8}. Best is trial 54 with value: 0.8858787135523333.\n",
      "[I 2024-08-27 18:47:25,116] Trial 59 finished with value: 0.8828065900589878 and parameters: {'learning_rate': 0.08278617442753412, 'n_estimators': 978, 'depth': 7}. Best is trial 54 with value: 0.8858787135523333.\n",
      "[I 2024-08-27 18:47:26,618] A new study created in memory with name: no-name-069a5e1f-9467-409c-99be-b07c1e1558d6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optuna search on the coreset data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 18:47:27,009] Trial 0 finished with value: 0.8544659769417942 and parameters: {'learning_rate': 0.1377128879552561, 'n_estimators': 700, 'depth': 5}. Best is trial 0 with value: 0.8544659769417942.\n",
      "[I 2024-08-27 18:47:27,773] Trial 1 finished with value: 0.8643363648010142 and parameters: {'learning_rate': 0.029557375450105294, 'n_estimators': 313, 'depth': 9}. Best is trial 1 with value: 0.8643363648010142.\n",
      "[I 2024-08-27 18:47:28,284] Trial 2 finished with value: 0.8595474128212424 and parameters: {'learning_rate': 0.08132312698992775, 'n_estimators': 898, 'depth': 10}. Best is trial 1 with value: 0.8643363648010142.\n",
      "[I 2024-08-27 18:47:28,578] Trial 3 finished with value: 0.8618930506275798 and parameters: {'learning_rate': 0.2697396676223111, 'n_estimators': 643, 'depth': 5}. Best is trial 1 with value: 0.8643363648010142.\n",
      "[I 2024-08-27 18:47:28,872] Trial 4 finished with value: 0.8615852630414292 and parameters: {'learning_rate': 0.26175367351292195, 'n_estimators': 774, 'depth': 5}. Best is trial 1 with value: 0.8643363648010142.\n",
      "[I 2024-08-27 18:47:29,204] Trial 5 finished with value: 0.8581894160899037 and parameters: {'learning_rate': 0.18847111843202025, 'n_estimators': 757, 'depth': 10}. Best is trial 1 with value: 0.8643363648010142.\n",
      "[I 2024-08-27 18:47:29,480] Trial 6 finished with value: 0.845023101846726 and parameters: {'learning_rate': 0.29598608688056777, 'n_estimators': 314, 'depth': 6}. Best is trial 1 with value: 0.8643363648010142.\n",
      "[I 2024-08-27 18:47:30,712] Trial 7 finished with value: 0.8646582560657576 and parameters: {'learning_rate': 0.020000065931637223, 'n_estimators': 572, 'depth': 5}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:31,263] Trial 8 finished with value: 0.860622477694117 and parameters: {'learning_rate': 0.06167512106792438, 'n_estimators': 358, 'depth': 9}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:31,555] Trial 9 finished with value: 0.8557594237406493 and parameters: {'learning_rate': 0.2805434984109465, 'n_estimators': 580, 'depth': 9}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:31,940] Trial 10 finished with value: 0.8619461495305799 and parameters: {'learning_rate': 0.13331057238817937, 'n_estimators': 532, 'depth': 12}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:33,013] Trial 11 finished with value: 0.8560556207710068 and parameters: {'learning_rate': 0.01744754716251347, 'n_estimators': 446, 'depth': 7}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:34,081] Trial 12 finished with value: 0.8567352927673633 and parameters: {'learning_rate': 0.010150802311348517, 'n_estimators': 456, 'depth': 7}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:34,606] Trial 13 finished with value: 0.8620994851978325 and parameters: {'learning_rate': 0.07356475971601405, 'n_estimators': 913, 'depth': 8}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:35,278] Trial 14 finished with value: 0.8609982156208258 and parameters: {'learning_rate': 0.04843304554346817, 'n_estimators': 434, 'depth': 12}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:35,706] Trial 15 finished with value: 0.8622824464589837 and parameters: {'learning_rate': 0.11380747289902515, 'n_estimators': 557, 'depth': 10}. Best is trial 7 with value: 0.8646582560657576.\n",
      "[I 2024-08-27 18:47:36,458] Trial 16 finished with value: 0.8653914743613135 and parameters: {'learning_rate': 0.03913861846557888, 'n_estimators': 378, 'depth': 8}. Best is trial 16 with value: 0.8653914743613135.\n",
      "[I 2024-08-27 18:47:36,786] Trial 17 finished with value: 0.8565566352916261 and parameters: {'learning_rate': 0.20159391155743211, 'n_estimators': 504, 'depth': 7}. Best is trial 16 with value: 0.8653914743613135.\n",
      "[I 2024-08-27 18:47:37,222] Trial 18 finished with value: 0.8551203882891689 and parameters: {'learning_rate': 0.10353671824005682, 'n_estimators': 395, 'depth': 6}. Best is trial 16 with value: 0.8653914743613135.\n",
      "[I 2024-08-27 18:47:37,565] Trial 19 finished with value: 0.8661672076520242 and parameters: {'learning_rate': 0.18177824672539616, 'n_estimators': 611, 'depth': 11}. Best is trial 19 with value: 0.8661672076520242.\n",
      "[I 2024-08-27 18:47:37,909] Trial 20 finished with value: 0.8629582760488906 and parameters: {'learning_rate': 0.18323632814035248, 'n_estimators': 987, 'depth': 11}. Best is trial 19 with value: 0.8661672076520242.\n",
      "[I 2024-08-27 18:47:38,248] Trial 21 finished with value: 0.8697937206735084 and parameters: {'learning_rate': 0.2424491483062709, 'n_estimators': 629, 'depth': 8}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:38,570] Trial 22 finished with value: 0.8628499485833337 and parameters: {'learning_rate': 0.23421094424134742, 'n_estimators': 631, 'depth': 8}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:38,886] Trial 23 finished with value: 0.8611997622231444 and parameters: {'learning_rate': 0.22130634712046207, 'n_estimators': 703, 'depth': 8}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:39,244] Trial 24 finished with value: 0.8552229167309362 and parameters: {'learning_rate': 0.16206591060950104, 'n_estimators': 817, 'depth': 11}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:39,559] Trial 25 finished with value: 0.8601692507856481 and parameters: {'learning_rate': 0.23392386103388968, 'n_estimators': 606, 'depth': 8}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:39,912] Trial 26 finished with value: 0.8551055119075817 and parameters: {'learning_rate': 0.1622340379677528, 'n_estimators': 505, 'depth': 11}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:40,256] Trial 27 finished with value: 0.8655511414769257 and parameters: {'learning_rate': 0.2513380005351562, 'n_estimators': 667, 'depth': 9}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:40,567] Trial 28 finished with value: 0.862306571806512 and parameters: {'learning_rate': 0.25137188943414585, 'n_estimators': 692, 'depth': 10}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:40,920] Trial 29 finished with value: 0.8675263199124786 and parameters: {'learning_rate': 0.2121870089770477, 'n_estimators': 691, 'depth': 9}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:41,246] Trial 30 finished with value: 0.8485312799485143 and parameters: {'learning_rate': 0.2044907687383008, 'n_estimators': 736, 'depth': 11}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:41,556] Trial 31 finished with value: 0.8540596372783349 and parameters: {'learning_rate': 0.24111864645071246, 'n_estimators': 677, 'depth': 9}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:41,879] Trial 32 finished with value: 0.8678026290675863 and parameters: {'learning_rate': 0.22357388419825322, 'n_estimators': 796, 'depth': 9}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:42,220] Trial 33 finished with value: 0.8646635971767486 and parameters: {'learning_rate': 0.21091325209395131, 'n_estimators': 820, 'depth': 10}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:42,595] Trial 34 finished with value: 0.8657403791656454 and parameters: {'learning_rate': 0.17490093281901298, 'n_estimators': 812, 'depth': 9}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:42,980] Trial 35 finished with value: 0.8623961204321784 and parameters: {'learning_rate': 0.14213579552785338, 'n_estimators': 887, 'depth': 7}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:43,323] Trial 36 finished with value: 0.8672686767015343 and parameters: {'learning_rate': 0.21771642356683493, 'n_estimators': 725, 'depth': 10}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:43,617] Trial 37 finished with value: 0.8558045382206839 and parameters: {'learning_rate': 0.27645156306426116, 'n_estimators': 732, 'depth': 10}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:43,933] Trial 38 finished with value: 0.8687858406896674 and parameters: {'learning_rate': 0.21719441890408298, 'n_estimators': 773, 'depth': 10}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:44,236] Trial 39 finished with value: 0.8584189767312277 and parameters: {'learning_rate': 0.28818519532244485, 'n_estimators': 782, 'depth': 9}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:44,552] Trial 40 finished with value: 0.865638788640003 and parameters: {'learning_rate': 0.2640780123489305, 'n_estimators': 867, 'depth': 9}. Best is trial 21 with value: 0.8697937206735084.\n",
      "[I 2024-08-27 18:47:44,890] Trial 41 finished with value: 0.8704215468054454 and parameters: {'learning_rate': 0.21645515362396792, 'n_estimators': 725, 'depth': 10}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:45,224] Trial 42 finished with value: 0.8604142450954732 and parameters: {'learning_rate': 0.19613418630085283, 'n_estimators': 777, 'depth': 10}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:45,548] Trial 43 finished with value: 0.8596173849322674 and parameters: {'learning_rate': 0.22339691337923764, 'n_estimators': 847, 'depth': 9}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:45,863] Trial 44 finished with value: 0.863160409074516 and parameters: {'learning_rate': 0.2508134198974921, 'n_estimators': 644, 'depth': 8}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:46,191] Trial 45 finished with value: 0.8607824765685902 and parameters: {'learning_rate': 0.23187461728513134, 'n_estimators': 932, 'depth': 10}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:46,499] Trial 46 finished with value: 0.8615176851315788 and parameters: {'learning_rate': 0.2983421821085212, 'n_estimators': 753, 'depth': 9}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:46,845] Trial 47 finished with value: 0.8625750561783762 and parameters: {'learning_rate': 0.1939231232048581, 'n_estimators': 707, 'depth': 9}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:47,198] Trial 48 finished with value: 0.8611145578700632 and parameters: {'learning_rate': 0.2122846068023923, 'n_estimators': 772, 'depth': 8}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:47,509] Trial 49 finished with value: 0.8663486635549958 and parameters: {'learning_rate': 0.2642010805694235, 'n_estimators': 661, 'depth': 7}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:47,827] Trial 50 finished with value: 0.854323447209876 and parameters: {'learning_rate': 0.242872084536109, 'n_estimators': 794, 'depth': 10}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:48,167] Trial 51 finished with value: 0.8595656131446854 and parameters: {'learning_rate': 0.2196980397850866, 'n_estimators': 722, 'depth': 10}. Best is trial 41 with value: 0.8704215468054454.\n",
      "[I 2024-08-27 18:47:48,523] Trial 52 finished with value: 0.8706688377102079 and parameters: {'learning_rate': 0.21007757800741864, 'n_estimators': 599, 'depth': 10}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:48,860] Trial 53 finished with value: 0.8565870923942638 and parameters: {'learning_rate': 0.19857417121512924, 'n_estimators': 579, 'depth': 11}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:49,221] Trial 54 finished with value: 0.867748750296871 and parameters: {'learning_rate': 0.18242528393040228, 'n_estimators': 623, 'depth': 9}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:49,565] Trial 55 finished with value: 0.8535294160714506 and parameters: {'learning_rate': 0.17394557391117382, 'n_estimators': 536, 'depth': 10}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:49,907] Trial 56 finished with value: 0.860284416507986 and parameters: {'learning_rate': 0.18812233393298783, 'n_estimators': 611, 'depth': 12}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:50,279] Trial 57 finished with value: 0.8502755302373852 and parameters: {'learning_rate': 0.15292283390405256, 'n_estimators': 553, 'depth': 8}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:50,619] Trial 58 finished with value: 0.8634037221064199 and parameters: {'learning_rate': 0.17573946329004592, 'n_estimators': 629, 'depth': 6}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:50,934] Trial 59 finished with value: 0.856507443366731 and parameters: {'learning_rate': 0.2292843221222054, 'n_estimators': 487, 'depth': 11}. Best is trial 52 with value: 0.8706688377102079.\n",
      "[I 2024-08-27 18:47:51,284] A new study created in memory with name: no-name-60b01023-9868-4e37-8cbd-89ad6f5d0d99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optuna search on the random data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 18:47:51,587] Trial 0 finished with value: 0.741899988542995 and parameters: {'learning_rate': 0.12851274590652492, 'n_estimators': 967, 'depth': 11}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:51,844] Trial 1 finished with value: 0.7144934146676952 and parameters: {'learning_rate': 0.20984325685279398, 'n_estimators': 714, 'depth': 12}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:52,175] Trial 2 finished with value: 0.7079638388865077 and parameters: {'learning_rate': 0.1041717525047092, 'n_estimators': 375, 'depth': 7}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:52,413] Trial 3 finished with value: 0.7177758648051611 and parameters: {'learning_rate': 0.2908348269289256, 'n_estimators': 509, 'depth': 12}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:52,653] Trial 4 finished with value: 0.6868370197247113 and parameters: {'learning_rate': 0.26854886368631636, 'n_estimators': 923, 'depth': 12}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:53,009] Trial 5 finished with value: 0.7154673757018052 and parameters: {'learning_rate': 0.09072363478111696, 'n_estimators': 358, 'depth': 6}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:53,316] Trial 6 finished with value: 0.7056587754729147 and parameters: {'learning_rate': 0.11085397744477835, 'n_estimators': 865, 'depth': 11}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:53,611] Trial 7 finished with value: 0.7159291038661505 and parameters: {'learning_rate': 0.12707224216952936, 'n_estimators': 642, 'depth': 11}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:53,882] Trial 8 finished with value: 0.7181274261148703 and parameters: {'learning_rate': 0.17180135889941112, 'n_estimators': 541, 'depth': 7}. Best is trial 0 with value: 0.741899988542995.\n",
      "[I 2024-08-27 18:47:54,174] Trial 9 finished with value: 0.7487732341288967 and parameters: {'learning_rate': 0.18975108729382276, 'n_estimators': 935, 'depth': 11}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:54,633] Trial 10 finished with value: 0.7170981807241366 and parameters: {'learning_rate': 0.05363592560188385, 'n_estimators': 775, 'depth': 9}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:54,899] Trial 11 finished with value: 0.7225541631723655 and parameters: {'learning_rate': 0.18436466780367325, 'n_estimators': 990, 'depth': 9}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:55,150] Trial 12 finished with value: 0.7259079432204973 and parameters: {'learning_rate': 0.23162201632355198, 'n_estimators': 838, 'depth': 10}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:56,079] Trial 13 finished with value: 0.7141557735895789 and parameters: {'learning_rate': 0.01876108738831439, 'n_estimators': 998, 'depth': 10}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:56,375] Trial 14 finished with value: 0.6940717670890467 and parameters: {'learning_rate': 0.14866383896399554, 'n_estimators': 903, 'depth': 10}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:56,630] Trial 15 finished with value: 0.6933516272482756 and parameters: {'learning_rate': 0.22937211990904702, 'n_estimators': 794, 'depth': 8}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:56,913] Trial 16 finished with value: 0.7154320678895302 and parameters: {'learning_rate': 0.1586209463266185, 'n_estimators': 663, 'depth': 5}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:57,314] Trial 17 finished with value: 0.7129232366845819 and parameters: {'learning_rate': 0.06661057879971012, 'n_estimators': 956, 'depth': 11}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:57,586] Trial 18 finished with value: 0.7173932140677854 and parameters: {'learning_rate': 0.20038081252096512, 'n_estimators': 765, 'depth': 8}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:57,872] Trial 19 finished with value: 0.7165037156145815 and parameters: {'learning_rate': 0.14327201050286728, 'n_estimators': 873, 'depth': 11}. Best is trial 9 with value: 0.7487732341288967.\n",
      "[I 2024-08-27 18:47:58,124] Trial 20 finished with value: 0.7523938771899249 and parameters: {'learning_rate': 0.2457047287288864, 'n_estimators': 536, 'depth': 10}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:47:58,377] Trial 21 finished with value: 0.7204137496611548 and parameters: {'learning_rate': 0.25558334541832084, 'n_estimators': 457, 'depth': 10}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:47:58,623] Trial 22 finished with value: 0.7013220031027797 and parameters: {'learning_rate': 0.24839198796299763, 'n_estimators': 590, 'depth': 9}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:47:58,887] Trial 23 finished with value: 0.723734658115349 and parameters: {'learning_rate': 0.19503902060816963, 'n_estimators': 472, 'depth': 11}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:47:59,131] Trial 24 finished with value: 0.7184708800013594 and parameters: {'learning_rate': 0.29630410392016404, 'n_estimators': 592, 'depth': 10}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:47:59,388] Trial 25 finished with value: 0.7165696829715984 and parameters: {'learning_rate': 0.21385572435298728, 'n_estimators': 406, 'depth': 12}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:47:59,658] Trial 26 finished with value: 0.7181111437842962 and parameters: {'learning_rate': 0.18172089377729606, 'n_estimators': 710, 'depth': 11}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:47:59,971] Trial 27 finished with value: 0.738558684291915 and parameters: {'learning_rate': 0.13375773784645323, 'n_estimators': 314, 'depth': 9}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:48:00,235] Trial 28 finished with value: 0.6944431197599902 and parameters: {'learning_rate': 0.22975411912302904, 'n_estimators': 950, 'depth': 10}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:48:00,515] Trial 29 finished with value: 0.7236104206515823 and parameters: {'learning_rate': 0.16494602886124987, 'n_estimators': 713, 'depth': 12}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:48:00,775] Trial 30 finished with value: 0.7162802112941372 and parameters: {'learning_rate': 0.21236217160179435, 'n_estimators': 821, 'depth': 12}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:48:01,080] Trial 31 finished with value: 0.7364327523463353 and parameters: {'learning_rate': 0.12930828945245224, 'n_estimators': 301, 'depth': 9}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:48:01,466] Trial 32 finished with value: 0.7119420311102752 and parameters: {'learning_rate': 0.07507033303412186, 'n_estimators': 302, 'depth': 8}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:48:01,794] Trial 33 finished with value: 0.7195606860054906 and parameters: {'learning_rate': 0.11676667112629546, 'n_estimators': 370, 'depth': 9}. Best is trial 20 with value: 0.7523938771899249.\n",
      "[I 2024-08-27 18:48:02,043] Trial 34 finished with value: 0.7557229065844626 and parameters: {'learning_rate': 0.2728366591009228, 'n_estimators': 438, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:02,289] Trial 35 finished with value: 0.7003516599448079 and parameters: {'learning_rate': 0.26626868123865116, 'n_estimators': 531, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:02,529] Trial 36 finished with value: 0.7072697837974201 and parameters: {'learning_rate': 0.2854876113885205, 'n_estimators': 426, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:02,775] Trial 37 finished with value: 0.7258438509858702 and parameters: {'learning_rate': 0.27486256276668747, 'n_estimators': 565, 'depth': 12}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:03,032] Trial 38 finished with value: 0.7469473179586561 and parameters: {'learning_rate': 0.24155334933713138, 'n_estimators': 499, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:03,279] Trial 39 finished with value: 0.6920452278492174 and parameters: {'learning_rate': 0.26303635969962247, 'n_estimators': 485, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:03,528] Trial 40 finished with value: 0.7125950020231046 and parameters: {'learning_rate': 0.23781548018794396, 'n_estimators': 626, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:03,769] Trial 41 finished with value: 0.7266244968218105 and parameters: {'learning_rate': 0.28079278477259934, 'n_estimators': 511, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:04,119] Trial 42 finished with value: 0.7137654802595458 and parameters: {'learning_rate': 0.09728847130751161, 'n_estimators': 419, 'depth': 12}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:04,369] Trial 43 finished with value: 0.7103263386170339 and parameters: {'learning_rate': 0.24413795191339766, 'n_estimators': 446, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:04,619] Trial 44 finished with value: 0.7039920761664485 and parameters: {'learning_rate': 0.2553006884550154, 'n_estimators': 499, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:04,875] Trial 45 finished with value: 0.7239438056004964 and parameters: {'learning_rate': 0.21945511655415353, 'n_estimators': 919, 'depth': 12}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:05,142] Trial 46 finished with value: 0.7037171784060587 and parameters: {'learning_rate': 0.19799215008541557, 'n_estimators': 549, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:05,377] Trial 47 finished with value: 0.7040319967669122 and parameters: {'learning_rate': 0.2992378448414176, 'n_estimators': 884, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:05,651] Trial 48 finished with value: 0.718030304048487 and parameters: {'learning_rate': 0.17392105492518262, 'n_estimators': 966, 'depth': 7}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:05,907] Trial 49 finished with value: 0.723334923523464 and parameters: {'learning_rate': 0.22471458708069184, 'n_estimators': 663, 'depth': 6}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:06,157] Trial 50 finished with value: 0.7073466408384307 and parameters: {'learning_rate': 0.2706502605492932, 'n_estimators': 339, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:06,460] Trial 51 finished with value: 0.7200843100202204 and parameters: {'learning_rate': 0.14229893277734604, 'n_estimators': 391, 'depth': 9}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:06,783] Trial 52 finished with value: 0.7149300120626494 and parameters: {'learning_rate': 0.12092100666566208, 'n_estimators': 342, 'depth': 9}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:07,083] Trial 53 finished with value: 0.7018721861826037 and parameters: {'learning_rate': 0.133293063322123, 'n_estimators': 513, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:07,401] Trial 54 finished with value: 0.708812068616358 and parameters: {'learning_rate': 0.11336904815668224, 'n_estimators': 580, 'depth': 8}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:07,672] Trial 55 finished with value: 0.7134002965353439 and parameters: {'learning_rate': 0.1569425266320064, 'n_estimators': 458, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:08,002] Trial 56 finished with value: 0.7152305090008647 and parameters: {'learning_rate': 0.10510139259930917, 'n_estimators': 616, 'depth': 9}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:08,685] Trial 57 finished with value: 0.7166524283482426 and parameters: {'learning_rate': 0.031259024745420735, 'n_estimators': 744, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:09,057] Trial 58 finished with value: 0.7247520020462109 and parameters: {'learning_rate': 0.08533741014318223, 'n_estimators': 932, 'depth': 10}. Best is trial 34 with value: 0.7557229065844626.\n",
      "[I 2024-08-27 18:48:09,316] Trial 59 finished with value: 0.7371271572761179 and parameters: {'learning_rate': 0.20324461488037307, 'n_estimators': 976, 'depth': 11}. Best is trial 34 with value: 0.7557229065844626.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>Log loss</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full_optuna</th>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>97.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coreset_optuna</th>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>24.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_optuna</th>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.7708</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>0.7557</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>18.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Balanced accuracy      F1  Precision  Recall  ROC AUC   AUPRC  \\\n",
       "Full_optuna                0.9081  0.8889     0.9756  0.8163   0.9765  0.8859   \n",
       "Coreset_optuna             0.9081  0.8602     0.9091  0.8163   0.9722  0.8707   \n",
       "Random_optuna              0.8774  0.7708     0.7872  0.7551   0.9454  0.7557   \n",
       "\n",
       "                Log loss   Time  \n",
       "Full_optuna       0.0022  97.33  \n",
       "Coreset_optuna    0.0025  24.32  \n",
       "Random_optuna     0.0038  18.03  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "optunaCV_stats = dict()\n",
    "tuning_data = service_obj.get_coreset(level=2, as_df=False)\n",
    "num_samples = service_obj.get_coreset_size(level=2)\n",
    "idx = np.random.choice(X_train.shape[0], num_samples, replace=False)\n",
    "random_train, random_train_target = X_train[idx], y_train[idx]\n",
    "\n",
    "def get_model_params(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 5, 12),\n",
    "    }\n",
    "\n",
    "def objective(trial, data_source, all_scores=False):\n",
    "    if all_scores:\n",
    "        param = trial.params\n",
    "    else:\n",
    "        param = get_model_params(trial)\n",
    "    model = model_class(**param)\n",
    "\n",
    "    if data_source == 'coreset':\n",
    "        model.fit(X=tuning_data['X'], y=tuning_data['y'], eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=100, sample_weight=tuning_data['w'])\n",
    "    elif data_source == 'random':\n",
    "        model.fit(random_train, random_train_target, eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=100)\n",
    "    else:  # full dataset\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=100)\n",
    "\n",
    "    balanced_acc, f1, precision, recall, roc_auc, auprc, log_loss_score = evaluate_model(model)\n",
    "    if all_scores:\n",
    "        return balanced_acc, f1, precision, recall, roc_auc, auprc, log_loss_score\n",
    "    return auprc\n",
    "\n",
    "def run_optuna_search(data_source, n_trials=60, timeout=600):\n",
    "    print(f\"Running optuna search on the {data_source} data\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    start_time = time.time()\n",
    "    study.optimize(lambda trial: objective(trial, data_source), n_trials=n_trials, timeout=timeout)\n",
    "    total_time = time.time() - start_time\n",
    "    best_trial = study.best_trial\n",
    "    balanced_acc, f1, precision, recall, roc_auc, auprc, log_loss_score = objective(best_trial, data_source, all_scores=True)\n",
    "    return {\n",
    "        \"Balanced accuracy\": balanced_acc,\n",
    "        \"F1\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"AUPRC\": auprc,\n",
    "        \"Log loss\": log_loss_score,\n",
    "        \"Time\": total_time,\n",
    "    }\n",
    " \n",
    "data_sources = ['full', 'coreset', 'random']\n",
    "for source in data_sources:\n",
    "    optunaCV_stats[f\"{source.capitalize()}_optuna\"] = run_optuna_search(source)\n",
    "\n",
    "# Create a DataFrame out of the stats\n",
    "optunaCV_stats_df = pd.DataFrame(optunaCV_stats).T\n",
    "optunaCV_stats_df['Time'] = optunaCV_stats_df['Time'].apply(lambda x: round(x, 2))\n",
    "for column in ['Balanced accuracy', 'F1', 'Precision', 'Recall', 'ROC AUC', 'AUPRC', 'Log loss']:\n",
    "    optunaCV_stats_df[column] = optunaCV_stats_df[column].map(lambda x: round(x, 4))\n",
    "optunaCV_stats_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
